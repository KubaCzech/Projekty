{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#RWKV - a parameter efficient language model based on recurrent neural networks (RNNs)\n",
        "\n",
        "Currently Transformer-based language models dominate our world, but recently a new attempt to use RNNs more effectively have been made.\n",
        "\n",
        "The result of this is RWKV, a parameter-efficient model that is really powerful. Even if it is small in size (the smallest model is just 100M parameters, where popular Transformer-based LLMs often are 10xbigger (or more)) it is of great quality.\n",
        "\n",
        "You can find the description of the model here:\n",
        "https://www.rwkv.com/\n",
        "\n",
        "And some demos here:\n",
        "\n",
        "https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-2 - a smaller, 0.1M parameters model\n",
        "\n",
        "\n",
        "https://huggingface.co/spaces/BlinkDL/RWKV-Gradio-1 - a bigger, 2.9B parameters model (theoretically it should be of higher quality)\n",
        "\n",
        "You can interact with those models by providing the \"prompt\", the starting text that the model will try to continue.\n",
        "\n",
        "A popular approach used here is to use a \"chat\" behaviour, where we introduce multiple roles in the text processed.\n",
        "Here, we state our query as the user (which is marked by the \"User:\" prefix) and if we want the network to answer, we end our prompt with the \"Assistant:\" text, so that the next (generated) tokens will be the naswers provided by the virtual assistant.\n",
        "\n",
        "Try to experiment with this model, check what it can do, if it understand queries stated in different languages (e.g., Polish), and what is the effect of the parameters we can provide (e.g., increasing the temperature should increase the creativeness of the model). At the bottom of the demo, you see some example prompts that you can explore."
      ],
      "metadata": {
        "id": "AAQXAmd8SSQO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "an3RQ1HTSN17"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}