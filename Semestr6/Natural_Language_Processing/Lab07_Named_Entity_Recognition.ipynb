{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDh0P1HI3sOF"
      },
      "source": [
        "# Named entity recognition\n",
        "\n",
        "Named entity recognition refers to the problem of extracting short fragments of texts and classifying them. Today, we will learn a new framework called FLAIR (we discussed this framework in our lecture). \n",
        "\n",
        "First, we will try to use a pretrained model using the FLAIR framework.\n",
        "\n",
        "**Assignment 1**\n",
        "Please visit the FLAIR website and read the documentation of FLAIR related to tagging entities: https://flairnlp.github.io/docs/tutorial-basics/tagging-entities . Use the code provided there to tag some example input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EmzXdXu13pmD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-06 23:26:44,270 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
            "Sentence[6]: \"George Washington went to Washington.\" â†’ [\"George Washington\"/PER, \"Washington\"/LOC]\n"
          ]
        }
      ],
      "source": [
        "from flair.data import Sentence\n",
        "from flair.nn import Classifier\n",
        "\n",
        "# make a sentence\n",
        "sentence = Sentence('George Washington went to Washington.')\n",
        "\n",
        "# load the NER tagger\n",
        "tagger = Classifier.load('ner-large')\n",
        "\n",
        "# run NER over sentence\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# print the sentence with all annotations\n",
        "print(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5E5OQSh5SRl"
      },
      "source": [
        "**(Optional)** Of course, most often, we would like to train our own tagger. The description providing details on this process can be found in a great blogpost (if you see a paywall you can open the website in the incognito mode). \n",
        "\n",
        "https://medium.com/thecyphy/training-custom-ner-model-using-flair-df1f9ea9c762\n",
        "\n",
        "However, training a custom FLAIR model is not required in this labs.\n",
        "\n",
        "\n",
        "**Assignment 2** Named Entity Recognition models can be also prepared using BERT and HuggingFace transformers library!\n",
        "\n",
        "To see how we can use transformers to solve a NER problem, we will use the notebook provided by Niels Rogge from HuggingFace. https://github.com/NielsRogge/Transformers-Tutorials . The notebook we will use is uploaded to eKursy along this \"main\" notebook. Please follow the instructions in this other notebook and copy-and-paste appropriate cell output as described below.\n",
        "\n",
        "\n",
        "One of the code cells provided in this notebook is the following one:\n",
        "```\n",
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report(labels, predictions))\n",
        "```\n",
        "If you manage to follow this tutorial, this pair of lines will produce evaluation metrics. Copy-and-paste them into the cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-pKU7536g7I"
      },
      "source": [
        "                        precision    recall  f1-score   support\n",
        "         geo             0.79      0.88      0.83      4613\n",
        "         gpe             0.89      0.89      0.89      1523\n",
        "         org             0.71      0.56      0.63      2761\n",
        "         per             0.78      0.81      0.79      2183\n",
        "         tim             0.82      0.81      0.81      1772\n",
        "      micro avg          0.79      0.79      0.79     12852\n",
        "      macro avg          0.80      0.79      0.79     12852\n",
        "      weighted avg       0.79      0.79      0.79     12852\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "                precision    recall  f1-score   support\n",
        "        geo       0.84      0.83      0.84     11232\n",
        "        gpe       0.93      0.89      0.91      3293\n",
        "        org       0.61      0.64      0.62      6531\n",
        "        per       0.76      0.79      0.77      5196\n",
        "        tim       0.84      0.76      0.80      4360\n",
        "        micro avg       0.78      0.78      0.78     30612\n",
        "        macro avg       0.79      0.78      0.79     30612\n",
        "        weighted avg       0.79      0.78      0.78     30612"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
