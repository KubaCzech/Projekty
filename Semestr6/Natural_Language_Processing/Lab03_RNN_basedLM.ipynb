{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIkhL_jaGt26"
      },
      "source": [
        "# RNN-based character level language model\n",
        "\n",
        "Below you can find an implementation of a character & RNN-based langauge model that predicts the next character given a sequence of elements we have.\n",
        "\n",
        "This simple implementation in PyTorch may give you a good overview on how those models behave and learn.\n",
        "\n",
        "This notebook does not introduce any tasks, you are free to experiment with the code, check what the input looks like, how it is encoded, how it is passed to the network and how the next character choice is made.\n",
        "\n",
        "You can try to use this code to generate the output sequence after the training stops, simply provide the context (some beginning of the text) and it should generate the sequence character after character until the end of sequence is reached (or, what is frequently used heuristics, a given number of elements is produced).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6h3taa2T_Bbn"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "dlopen(/Users/Kuba/Library/Python/3.9/lib/python/site-packages/blingfire/libblingfiretokdll.dylib, 0x0006): tried: '/Users/Kuba/Library/Python/3.9/lib/python/site-packages/blingfire/libblingfiretokdll.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/Kuba/Library/Python/3.9/lib/python/site-packages/blingfire/libblingfiretokdll.dylib' (no such file), '/Users/Kuba/Library/Python/3.9/lib/python/site-packages/blingfire/libblingfiretokdll.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64'))",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# blingfire can split texts into sentences\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mblingfire\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbf\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_ulysses\u001b[39m():\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    This function downloads Ulysses -- a famous book written by J. Joyce.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m    :return: The text of the book.\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/blingfire/__init__.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# detect Mac OSX\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m platform\u001b[38;5;241m.\u001b[39msystem() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDarwin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     blingfire \u001b[38;5;241m=\u001b[39m \u001b[43mcdll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibblingfiretokdll.dylib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# detect linux\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     blingfire \u001b[38;5;241m=\u001b[39m cdll\u001b[38;5;241m.\u001b[39mLoadLibrary(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibblingfiretokdll.so\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:444\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:366\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
            "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/Kuba/Library/Python/3.9/lib/python/site-packages/blingfire/libblingfiretokdll.dylib, 0x0006): tried: '/Users/Kuba/Library/Python/3.9/lib/python/site-packages/blingfire/libblingfiretokdll.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Users/Kuba/Library/Python/3.9/lib/python/site-packages/blingfire/libblingfiretokdll.dylib' (no such file), '/Users/Kuba/Library/Python/3.9/lib/python/site-packages/blingfire/libblingfiretokdll.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64'))"
          ]
        }
      ],
      "source": [
        "# install package for sentence splitting\n",
        "# !pip install blingfire\n",
        "\n",
        "# import pytorch-related stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# requests will help us download some data\n",
        "import requests\n",
        "\n",
        "# blingfire can split texts into sentences\n",
        "import blingfire as bf\n",
        "\n",
        "\n",
        "def download_ulysses():\n",
        "    \"\"\"\n",
        "    This function downloads Ulysses -- a famous book written by J. Joyce.\n",
        "\n",
        "    :return: The text of the book.\n",
        "    \"\"\"\n",
        "    url = \"https://www.gutenberg.org/files/4300/4300-0.txt\"\n",
        "    response = requests.get(url)\n",
        "    data = None\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.text\n",
        "    else:\n",
        "        print(\"Failed to download. Status code:\", response.status_code)\n",
        "    return data\n",
        "\n",
        "\n",
        "def split_into_sentences(text):\n",
        "    \"\"\"\n",
        "    Splits a given text into sentences using BlingFire.\n",
        "\n",
        "    :param text: The input text string.\n",
        "    :return: A list of sentences.\n",
        "    \"\"\"\n",
        "    sentences = bf.text_to_sentences(text).split('\\n')\n",
        "    return [s.strip() for s in sentences if s.strip()]\n",
        "\n",
        "\n",
        "\n",
        "class CharRNN(nn.Module):\n",
        "    \"\"\" Simple RNN network with one input layer, one hidden layer, and one output layer. \"\"\"\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CharRNN, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size                   # hidden size = embedding size\n",
        "        self.rnn = nn.RNNCell(input_size, hidden_size)   # recurrent cell that concumes the current input and the previous hidden state\n",
        "        self.fc = nn.Linear(hidden_size, output_size)    # output transformation that transforms the hidden state into the output layer (ie., decisions)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Implement the forward pass of the network. At each timestep,\n",
        "        we consume our current input (x) and the hidden state (hidden)\n",
        "        and produce an updated hidden state along with\n",
        "        the output of the whole network\n",
        "        \"\"\"\n",
        "\n",
        "        hidden = self.rnn(x, hidden)  # update hidden state based on current input and previous state\n",
        "        output = self.fc(hidden)      # calculate the output of the network by processing the hidden state with a fully-connected (fc) layer\n",
        "        return output, hidden         # return both\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        \"\"\"\n",
        "        Init hidden state with zero, required for generating the first step when there is no previous hidden state to be used. We use zeros in that case.\n",
        "        \"\"\"\n",
        "        return torch.zeros(batch_size, self.hidden_size)\n",
        "\n",
        "\n",
        "def char_tensor(text, char_to_idx):\n",
        "    \"\"\"\n",
        "    Transform a given text into one hot representations, where each letter is represented as one-hot encoding.\n",
        "    Here you can find more on one-hot representation: https://www.kaggle.com/code/dansbecker/using-categorical-data-with-one-hot-encoding\n",
        "    \"\"\"\n",
        "\n",
        "    # each character in our text will be represented as\n",
        "    # a vector of the length equal to the number of distinct characters in our dataset.\n",
        "    # Then we assign each position in that vector with different character and encode\n",
        "    #a given character by setting 1 on its position in the vector, while keeping other values set to 0.\n",
        "\n",
        "    tensor = torch.zeros(len(text), len(char_to_idx))\n",
        "\n",
        "    for i, char in enumerate(text):        # for each character (char) and its position in text (i)\n",
        "        tensor[i][char_to_idx[char]] = 1   # apply one-hot encoding for that character\n",
        "    return tensor\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    text = download_ulysses() # download the dataset\n",
        "    sentences = split_into_sentences(text) #split into sentences, 1 sentence will form one training example\n",
        "    chars = list(set(text))   # capture all characters found in our text\n",
        "    chars.append('\\\\')        # add a special character that will be used to encode the end of the sequence (sentence)\n",
        "\n",
        "    char_to_idx = {char: idx for idx, char in enumerate(chars)}  # create a mapping of known characters to their positions\n",
        "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}  # and a mapping of positions to characters\n",
        "\n",
        "    input_size = len(chars)       # the size of the input layer is the number of distinct characters observed, at each timestep, we provide a single character, that we encode using one-hot representation\n",
        "    hidden_size = 128             # what is the embedding length\n",
        "    output_size = len(chars)      # the same story as with the input layer, we transform hidden state into a character that will be the next one\n",
        "\n",
        "    model = CharRNN(input_size, hidden_size, output_size) # instantiate the model!\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)   # and configure training-related stuff\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    n_epochs = 500  # how many epochs should we apply?\n",
        "\n",
        "    for epoch in range(n_epochs):  # for each epoch\n",
        "        total_loss = 0  # start collecting cumulative loss that will help observe progress\n",
        "\n",
        "        for idx, instance in enumerate(sentences): # for each sentence\n",
        "            hidden = model.init_hidden(1)          # init the \"previous\" hidden state at the first step - set it to zero\n",
        "            input_seq = char_tensor(instance, char_to_idx) # encode our instance as one-hot encoding\n",
        "            target_seq = torch.tensor([char_to_idx[c] for c in instance[1:] + '\\\\']) # for each input_seq element, predict the subsequent character. At the end, when processing the last character, set \"\\\\\" as the target token representing the end of sequence.\n",
        "\n",
        "            optimizer.zero_grad()  # zero gradients\n",
        "            loss = 0  # zero loss\n",
        "            for i in range(len(instance)): # for each character in our sentence\n",
        "                input_char = input_seq[i].unsqueeze(0)  # take the current character,   Shape (1, input_size)\n",
        "                target_char = target_seq[i].unsqueeze(0)  # take the next character (that we want to predict) # Shape (1,)\n",
        "                output, hidden = model(input_char, hidden) # check what the model produces\n",
        "                loss += criterion(output, target_char)   # and compare the produced outcome with the expected (true) next character\n",
        "\n",
        "            loss.backward() # apply optimization procedure\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if idx == 5000:\n",
        "                break\n",
        "\n",
        "            if idx % 1000 == 0:\n",
        "                print(f'Epoch {epoch}, sentence {idx} cumulative loss: {total_loss:.4f} item loss: {loss.item()}')\n",
        "\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {total_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IFeagIu_G6Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
