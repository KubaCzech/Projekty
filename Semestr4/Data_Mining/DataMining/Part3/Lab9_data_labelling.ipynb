{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snorkel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lab is to introduce students to the [Snorkel](http://www.snorkel.org) tool and the possibilities of programmatic label generation using the weak-supervised learning paradigm.\n",
    "\n",
    "In order to use weakly supervised learning to generate labels, it is necessary to create three datasets:\n",
    "\n",
    "- **train set**: which does not have any labels\n",
    "- **validation set**: used for hyperparameter optimization, has labels\n",
    "- **test set**: used only for final model evaluation, has labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling functions\n",
    "\n",
    "The first step will be to load the dataset and split it into a train set and a test set. Since in our set all SMS have a label, we will simulate a weakly supervised learning problem by randomly removing 80% of the labels. Additionally, Snorkel requires numeric labels, so we need to recode the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:04.995959Z",
     "start_time": "2021-05-19T19:35:04.879076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "ham\tOk lar... Joking wif u oni...\n",
      "spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "ham\tU dun say so early hor... U c already then say...\n",
      "ham\tNah I don't think he goes to usf, he lives around here though\n",
      "spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
      "ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n"
     ]
    }
   ],
   "source": [
    "!head datasets/smsspamcollection.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:05.564736Z",
     "start_time": "2021-05-19T19:35:05.335569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&amp;C's apply 08452810075over18's</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                          text  \\\n",
       "0                                              Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...   \n",
       "1                                                                                                                                Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's   \n",
       "3                                                                                                            U dun say so early hor... U c already then say...   \n",
       "4                                                                                                Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3     -1  \n",
       "4     -1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('max_colwidth', 600)\n",
    "\n",
    "SPAM = 1\n",
    "HAM = 0\n",
    "ABSTAIN = -1\n",
    "\n",
    "df = pd.read_csv('./datasets/smsspamcollection.csv', sep='\\t', header=None, names=['old_label', 'text'])\n",
    "\n",
    "df['label'] = df.old_label.apply(lambda x: SPAM if x == 'spam' else HAM)\n",
    "\n",
    "df.loc[df.sample(frac=0.8).index, 'label'] = ABSTAIN\n",
    "df.drop(columns=['old_label'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:05.899853Z",
     "start_time": "2021-05-19T19:35:05.891864Z"
    }
   },
   "outputs": [],
   "source": [
    "abstain_idx = df.label == ABSTAIN\n",
    "\n",
    "df_train = df[abstain_idx]\n",
    "df_test = df[~abstain_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple keyword search\n",
    "\n",
    "As a first example, we will use a search for the words \"check\" and \"free\" in SMS content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:07.160530Z",
     "start_time": "2021-05-19T19:35:06.743723Z"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function()\n",
    "def check(sms):\n",
    "    return SPAM if \"check\" in sms.text.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def free(sms):\n",
    "    return SPAM if \"free\" in sms.text.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to apply the labeling functions to the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:07.664922Z",
     "start_time": "2021-05-19T19:35:07.537784Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:00<00:00, 85305.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [check, free]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of applying the set of labeling functions to the train set is a matrix of size $m \\times n$, where $m$ is the number of examples and $n$ is the number of labeling functions. The matrix contains the result of applying each function to each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:08.394943Z",
     "start_time": "2021-05-19T19:35:08.383414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, -1],\n",
       "       [-1, -1],\n",
       "       [-1,  1],\n",
       "       ...,\n",
       "       [-1, -1],\n",
       "       [-1,  1],\n",
       "       [-1, -1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:08.802557Z",
     "start_time": "2021-05-19T19:35:08.794050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     Nah I don't think he goes to usf, he lives around here though\n",
       "label                                                               -1\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to analyze this is to determine the coverage of labeling functions (i.e., the percentage of cases for which the function returned a result other than `ABSTAIN'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:09.658152Z",
     "start_time": "2021-05-19T19:35:09.652780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage for check(): 1.0%\n",
      "Coverage for free(): 4.4%\n"
     ]
    }
   ],
   "source": [
    "coverage_check, coverage_free = (L_train != ABSTAIN).mean(axis=0)\n",
    "\n",
    "print(f\"Coverage for check(): {coverage_check * 100:.1f}%\")\n",
    "print(f\"Coverage for free(): {coverage_free * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, Snorkel offers additional tools that allow for deeper analysis of the result of labeling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:10.422401Z",
     "start_time": "2021-05-19T19:35:10.392383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       j Polarity  Coverage  Overlaps  Conflicts\n",
       "check  0      [1]  0.010319       0.0        0.0\n",
       "free   1      [1]  0.043517       0.0        0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of each column is as follows:\n",
    "- `Polarity`: the set of labels returned by the function\n",
    "- `Coverage`: the percentage of examples for which the function returns a value other than `ABSTAIN`\n",
    "- Overlaps: the percentage of examples for which at least one other labeling function returned a value\n",
    "- Conflicts: the percentage of examples for which at least one other labeling function returned a different value\n",
    "\n",
    "If the train set contained labels, the method would also return:\n",
    "- `Correct`: the number of correct labels\n",
    "- `Incorrect`: number of incorrect labels\n",
    "- `Empirical Accuracy`: the percentage of correct labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the examples labeled by the `free()` function as spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:11.544719Z",
     "start_time": "2021-05-19T19:35:11.527030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Free video camera phones with Half Price line rental for 12 mths and 500 cross ntwk mins 100 txts. Call MobileUpd8 08001950382 or Call2OptOut/674&amp;</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>Mila, age23, blonde, new in UK. I look sex with UK guys. if u like fun with me. Text MTALK to 69866.18 . 30pp/txt 1st 5free. £1.50 increments. Help08718728876</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>Freemsg: 1-month unlimited free calls! Activate SmartCall Txt: CALL to No: 68866. Subscriptn3gbp/wk unlimited calls Help: 08448714184 Stop?txt stop landlineonly</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>Thanks for the Vote. Now sing along with the stars with Karaoke on your mobile. For a FREE link just reply with SING now.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Ringtone Club: Get the UK singles chart on your mobile each week and choose any top quality ringtone! This message is free of charge.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2189</th>\n",
       "      <td>FREE camera phones with linerental from 4.49/month with 750 cross ntwk mins. 1/2 price txt bundle deals also avble. Call 08001950382 or call2optout/J MF</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>FREE entry into our £250 weekly comp just send the word ENTER to 84128 NOW. 18 T&amp;C www.textcomp.com cust care 08712405020.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>Call FREEPHONE 0800 542 0578 now!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5342</th>\n",
       "      <td>u r subscribed 2 TEXTCOMP 250 wkly comp. 1st wk?s free question follows, subsequent wks charged@150p/msg.2 unsubscribe txt STOP 2 84128,custcare 08712405020</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>Xmas Offer! Latest Motorola, SonyEricsson &amp; Nokia &amp; FREE Bluetooth or DVD! Double Mins &amp; 1000 Txt on Orange. Call MobileUpd8 on 08000839402 or call2optout/4QF2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>Hey now am free you can call me.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>TheMob&gt;Hit the link to get a premium Pink Panther game, the new no. 1 from Sugababes, a crazy Zebra animation or a badass Hoody wallpaper-all 4 FREE!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>December only! Had your mobile 11mths+? You are entitled to update to the latest colour camera mobile for Free! Call The Mobile Update VCo FREE on 08002986906</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>Today i'm not workin but not free oso... Gee... Thgt u workin at ur fren's shop ?</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>Sppok up ur mob with a Halloween collection of nokia logo&amp;pic message plus a FREE eerie tone, txt CARD SPOOK to 8007</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>We tried to call you re your reply to our sms for a video mobile 750 mins UNLIMITED TEXT + free camcorder Reply of call 08000930705 Now</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>You have won a guaranteed £200 award or even £1000 cashto claim UR award call free on 08000407165 (18+) 2 stop getstop on 88222 PHP. RG21 4JX</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>Free entry in 2 a weekly comp for a chance to win an ipod. Txt POD to 80182 to get entry (std txt rate) T&amp;C's apply 08452810073 for details 18+</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                  text  \\\n",
       "3972                Free video camera phones with Half Price line rental for 12 mths and 500 cross ntwk mins 100 txts. Call MobileUpd8 08001950382 or Call2OptOut/674&   \n",
       "4587    Mila, age23, blonde, new in UK. I look sex with UK guys. if u like fun with me. Text MTALK to 69866.18 . 30pp/txt 1st 5free. £1.50 increments. Help08718728876   \n",
       "3423  Freemsg: 1-month unlimited free calls! Activate SmartCall Txt: CALL to No: 68866. Subscriptn3gbp/wk unlimited calls Help: 08448714184 Stop?txt stop landlineonly   \n",
       "1507                                         Thanks for the Vote. Now sing along with the stars with Karaoke on your mobile. For a FREE link just reply with SING now.   \n",
       "270                              Ringtone Club: Get the UK singles chart on your mobile each week and choose any top quality ringtone! This message is free of charge.   \n",
       "2189          FREE camera phones with linerental from 4.49/month with 750 cross ntwk mins. 1/2 price txt bundle deals also avble. Call 08001950382 or call2optout/J MF   \n",
       "1229                                        FREE entry into our £250 weekly comp just send the word ENTER to 84128 NOW. 18 T&C www.textcomp.com cust care 08712405020.   \n",
       "1777                                                                                                                                 Call FREEPHONE 0800 542 0578 now!   \n",
       "5342      u r subscribed 2 TEXTCOMP 250 wkly comp. 1st wk?s free question follows, subsequent wks charged@150p/msg.2 unsubscribe txt STOP 2 84128,custcare 08712405020   \n",
       "2980   Xmas Offer! Latest Motorola, SonyEricsson & Nokia & FREE Bluetooth or DVD! Double Mins & 1000 Txt on Orange. Call MobileUpd8 on 08000839402 or call2optout/4QF2   \n",
       "2952                                                                                                                                  Hey now am free you can call me.   \n",
       "5098             TheMob>Hit the link to get a premium Pink Panther game, the new no. 1 from Sugababes, a crazy Zebra animation or a badass Hoody wallpaper-all 4 FREE!   \n",
       "5112   December only! Had your mobile 11mths+? You are entitled to update to the latest colour camera mobile for Free! Call The Mobile Update VCo FREE on 08002986906    \n",
       "2858                                                                                Today i'm not workin but not free oso... Gee... Thgt u workin at ur fren's shop ?    \n",
       "2480                                              Sppok up ur mob with a Halloween collection of nokia logo&pic message plus a FREE eerie tone, txt CARD SPOOK to 8007   \n",
       "4091                           We tried to call you re your reply to our sms for a video mobile 750 mins UNLIMITED TEXT + free camcorder Reply of call 08000930705 Now   \n",
       "9           Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030   \n",
       "804                      You have won a guaranteed £200 award or even £1000 cashto claim UR award call free on 08000407165 (18+) 2 stop getstop on 88222 PHP. RG21 4JX   \n",
       "1904                   Free entry in 2 a weekly comp for a chance to win an ipod. Txt POD to 80182 to get entry (std txt rate) T&C's apply 08452810073 for details 18+   \n",
       "\n",
       "      label  \n",
       "3972     -1  \n",
       "4587     -1  \n",
       "3423     -1  \n",
       "1507     -1  \n",
       "270      -1  \n",
       "2189     -1  \n",
       "1229     -1  \n",
       "1777     -1  \n",
       "5342     -1  \n",
       "2980     -1  \n",
       "2952     -1  \n",
       "5098     -1  \n",
       "5112     -1  \n",
       "2858     -1  \n",
       "2480     -1  \n",
       "4091     -1  \n",
       "9        -1  \n",
       "804      -1  \n",
       "1904     -1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[L_train[:,1] == SPAM].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the phrase \"call now\" is also a good indicator for spam. So let's add one more labeling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:12.390882Z",
     "start_time": "2021-05-19T19:35:12.232917Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:00<00:00, 64499.49it/s]\n"
     ]
    }
   ],
   "source": [
    "@labeling_function()\n",
    "def call_now(sms):\n",
    "    return SPAM if \"call now\" in sms.text.lower() else ABSTAIN\n",
    "\n",
    "lfs = [check, free, call_now]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:12.520535Z",
     "start_time": "2021-05-19T19:35:12.493371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          j Polarity  Coverage  Overlaps  Conflicts\n",
       "check     0      [1]  0.010319  0.000000        0.0\n",
       "free      1      [1]  0.043517  0.001346        0.0\n",
       "call_now  2      [1]  0.004262  0.001346        0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which examples were labeled as spam by the `call_now()` function but omitted by `free()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:13.266968Z",
     "start_time": "2021-05-19T19:35:13.238111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(-1, -1): array([   0,    1,    3, ..., 4454, 4455, 4457]),\n",
       " (1,\n",
       "  -1): array([   2,    6,    9,   47,   61,   76,  111,  118,  145,  146,  153,\n",
       "         182,  213,  214,  236,  254,  290,  304,  318,  362,  392,  397,\n",
       "         419,  490,  497,  516,  537,  551,  579,  636,  640,  654,  655,\n",
       "         707,  734,  772,  816,  821,  830,  891,  971, 1000, 1002, 1037,\n",
       "        1099, 1109, 1121, 1176, 1187, 1214, 1224, 1225, 1234, 1249, 1255,\n",
       "        1279, 1308, 1323, 1331, 1352, 1380, 1431, 1439, 1442, 1444, 1495,\n",
       "        1536, 1543, 1617, 1673, 1676, 1696, 1706, 1734, 1758, 1794, 1851,\n",
       "        1861, 1883, 1900, 1953, 1986, 2015, 2066, 2101, 2117, 2132, 2243,\n",
       "        2278, 2286, 2300, 2302, 2318, 2362, 2386, 2395, 2405, 2415, 2494,\n",
       "        2499, 2502, 2515, 2543, 2572, 2610, 2645, 2685, 2704, 2721, 2732,\n",
       "        2733, 2749, 2788, 2798, 2816, 2922, 2953, 2967, 2982, 3007, 3017,\n",
       "        3051, 3078, 3083, 3110, 3134, 3158, 3161, 3176, 3182, 3206, 3209,\n",
       "        3236, 3251, 3262, 3269, 3274, 3322, 3323, 3326, 3332, 3361, 3363,\n",
       "        3365, 3377, 3387, 3439, 3444, 3445, 3513, 3579, 3634, 3658, 3659,\n",
       "        3666, 3775, 3778, 3817, 3900, 3921, 3924, 3948, 3959, 3960, 3963,\n",
       "        4053, 4055, 4058, 4070, 4085, 4089, 4095, 4108, 4118, 4122, 4123,\n",
       "        4145, 4161, 4170, 4243, 4277, 4286, 4308, 4328, 4357, 4368, 4452,\n",
       "        4456]),\n",
       " (1, 1): array([  34,  369,  399,  648, 2154, 3198]),\n",
       " (-1,\n",
       "  1): array([ 713, 1221, 1742, 2279, 2397, 2535, 3112, 3260, 3289, 3427, 3500,\n",
       "        3834, 4382])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.analysis import get_label_buckets\n",
    "\n",
    "buckets = get_label_buckets(L_train[:, 1], L_train[:, 2]) #we apply only second and third labeling function\n",
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:13.561565Z",
     "start_time": "2021-05-19T19:35:13.544427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Shop till u Drop, IS IT YOU, either 10K, 5K, £500 Cash or £100 Travel voucher, Call now, 09064011000. NTT PO Box CR01327BT fixedline Cost 150ppm mobile vary</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national rate call</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>Shop till u Drop, IS IT YOU, either 10K, 5K, £500 Cash or £100 Travel voucher, Call now, 09064011000. NTT PO Box CR01327BT fixedline Cost 150ppm mobile vary</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>YOUR CHANCE TO BE ON A REALITY FANTASY SHOW call now = 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national = rate call</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national rate call</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870..k</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>URGENT This is our 2nd attempt to contact U. Your £900 prize from YESTERDAY is still awaiting collection. To claim CALL NOW 09061702893. ACL03530150PM</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>Loans for any purpose even if you have Bad Credit! Tenants Welcome. Call NoWorriesLoans.com on 08717111821</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>HOT LIVE FANTASIES call now 08707500020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national rate call</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>U can call now...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>Do you want a new Video handset? 750 any time any network mins? UNLIMITED TEXT? Camcorder? Reply or Call now 08000930705 for del Sat AM</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>URGENT This is our 2nd attempt to contact U. Your £900 prize from YESTERDAY is still awaiting collection. To claim CALL NOW 09061702893</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>Shall call now dear having food</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                              text  \\\n",
       "876   Shop till u Drop, IS IT YOU, either 10K, 5K, £500 Cash or £100 Travel voucher, Call now, 09064011000. NTT PO Box CR01327BT fixedline Cost 150ppm mobile vary   \n",
       "1502                                    HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national rate call   \n",
       "2170  Shop till u Drop, IS IT YOU, either 10K, 5K, £500 Cash or £100 Travel voucher, Call now, 09064011000. NTT PO Box CR01327BT fixedline Cost 150ppm mobile vary   \n",
       "2850       YOUR CHANCE TO BE ON A REALITY FANTASY SHOW call now = 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national = rate call   \n",
       "2992                                    HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national rate call   \n",
       "3167                                                         HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870..k   \n",
       "3893        URGENT This is our 2nd attempt to contact U. Your £900 prize from YESTERDAY is still awaiting collection. To claim CALL NOW 09061702893. ACL03530150PM   \n",
       "4073                                                    Loans for any purpose even if you have Bad Credit! Tenants Welcome. Call NoWorriesLoans.com on 08717111821   \n",
       "4108                                    HOT LIVE FANTASIES call now 08707500020 Just 20p per min NTT Ltd, PO Box 1327 Croydon CR9 5WB 0870 is a national rate call   \n",
       "4283                                                                                                                                             U can call now...   \n",
       "4371                       Do you want a new Video handset? 750 any time any network mins? UNLIMITED TEXT? Camcorder? Reply or Call now 08000930705 for del Sat AM   \n",
       "4797                       URGENT This is our 2nd attempt to contact U. Your £900 prize from YESTERDAY is still awaiting collection. To claim CALL NOW 09061702893   \n",
       "5481                                                                                                                               Shall call now dear having food   \n",
       "\n",
       "      label  \n",
       "876      -1  \n",
       "1502     -1  \n",
       "2170     -1  \n",
       "2850     -1  \n",
       "2992     -1  \n",
       "3167     -1  \n",
       "3893     -1  \n",
       "4073     -1  \n",
       "4108     -1  \n",
       "4283     -1  \n",
       "4371     -1  \n",
       "4797     -1  \n",
       "5481     -1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[buckets[(ABSTAIN, SPAM)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:14.070016Z",
     "start_time": "2021-05-19T19:35:14.050884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          j Polarity  Coverage  Overlaps  Conflicts\n",
       "check     0      [1]  0.010319  0.000000        0.0\n",
       "free      1      [1]  0.043517  0.001346        0.0\n",
       "call_now  2      [1]  0.004262  0.001346        0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assignment\n",
    "\n",
    "Write a labeling function that marks as spam all messages containing the word \"HOT\" written in capitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:15.054371Z",
     "start_time": "2021-05-19T19:35:15.048930Z"
    }
   },
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def hot(sms):\n",
    "    return SPAM if \"HOT\" in sms.text else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching based on a regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another type of labeling function is one that uses regexp to find specific expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:16.266072Z",
     "start_time": "2021-05-19T19:35:15.979235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:00<00:00, 29859.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_I_am_free</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 j Polarity  Coverage  Overlaps  Conflicts\n",
       "check            0      [1]  0.010319  0.000000   0.000000\n",
       "free             1      [1]  0.043517  0.043517   0.006057\n",
       "call_now         2      [1]  0.004262  0.001346   0.000000\n",
       "regex_I_am_free  3   [0, 1]  0.043517  0.043517   0.006057"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "@labeling_function()\n",
    "def regex_I_am_free(sms):\n",
    "    if re.search(r\"I\\s.*free\", sms.text, flags=re.I): #flags = re.I -> ignore case\n",
    "        return HAM\n",
    "    elif re.search(r\"free\", sms.text, flags=re.I):\n",
    "        return SPAM\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "lfs = [check, free, call_now, regex_I_am_free]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare examples that the `free()` function labels as spam and the `regex_I_am_free()` function considers valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:17.020431Z",
     "start_time": "2021-05-19T19:35:16.996219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>oh ya... Got hip hop open. Haha i was thinking can go for jazz then zoom to cine... Actually tonight i'm free leh... And there's a kb lesson tonight</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>I not free today i haf 2 pick my parents up tonite...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>I got to video tape pple type in message lor. U so free wan 2 help me? Hee... Cos i noe u wan 2 watch infernal affairs so ask u along. Asking shuhui oso.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Yetunde, i'm sorry but moji and i seem too busy to be able to go shopping. Can you just please find some other way to get what you wanted us to get. Please forgive me. You can reply free via yahoo messenger.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>Hi this is Amy, we will be sending you a free phone number in a couple of days, which will give you an access to all the adult parties...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>I want snow. It's just freezing and windy.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>Do you want a New Nokia 3510i Colour Phone Delivered Tomorrow? With 200 FREE minutes to any mobile + 100 FREE text + FREE camcorder Reply or Call 8000930705</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>Lemme know when I can swing by and pick up, I'm free basically any time after 1 all this semester</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>Hi if ur lookin 4 saucy daytime fun wiv busty married woman Am free all next week Chat now 2 sort time 09099726429 JANINExx Calls£1/minMobsmoreLKPOBOX177HP51FL</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>Hey i booked the kb on sat already... what other lessons are we going for ah? Keep your sat night free we need to meet and confirm our lodging</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                 text  \\\n",
       "3855                                                             oh ya... Got hip hop open. Haha i was thinking can go for jazz then zoom to cine... Actually tonight i'm free leh... And there's a kb lesson tonight   \n",
       "3526                                                                                                                                                            I not free today i haf 2 pick my parents up tonite...   \n",
       "3951                                                        I got to video tape pple type in message lor. U so free wan 2 help me? Hee... Cos i noe u wan 2 watch infernal affairs so ask u along. Asking shuhui oso.   \n",
       "1364  Yetunde, i'm sorry but moji and i seem too busy to be able to go shopping. Can you just please find some other way to get what you wanted us to get. Please forgive me. You can reply free via yahoo messenger.   \n",
       "4949                                                                        Hi this is Amy, we will be sending you a free phone number in a couple of days, which will give you an access to all the adult parties...   \n",
       "3216                                                                                                                                                                       I want snow. It's just freezing and windy.   \n",
       "4386                                                     Do you want a New Nokia 3510i Colour Phone Delivered Tomorrow? With 200 FREE minutes to any mobile + 100 FREE text + FREE camcorder Reply or Call 8000930705   \n",
       "4471                                                                                                                Lemme know when I can swing by and pick up, I'm free basically any time after 1 all this semester   \n",
       "1663                                                  Hi if ur lookin 4 saucy daytime fun wiv busty married woman Am free all next week Chat now 2 sort time 09099726429 JANINExx Calls£1/minMobsmoreLKPOBOX177HP51FL   \n",
       "948                                                                   Hey i booked the kb on sat already... what other lessons are we going for ah? Keep your sat night free we need to meet and confirm our lodging    \n",
       "\n",
       "      label  \n",
       "3855     -1  \n",
       "3526     -1  \n",
       "3951     -1  \n",
       "1364     -1  \n",
       "4949     -1  \n",
       "3216     -1  \n",
       "4386     -1  \n",
       "4471     -1  \n",
       "1663     -1  \n",
       "948      -1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets = get_label_buckets(L_train[:, 1], L_train[:, 3])\n",
    "df_train.iloc[buckets[(SPAM, HAM)]].sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assignment\n",
    "\n",
    "Write a labeling function that will mark as spam all messages containing any amounts specified with a currency symbol ($99, £1.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:18.671866Z",
     "start_time": "2021-05-19T19:35:18.669094Z"
    }
   },
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def contains_money(sms):\n",
    "    return SPAM if re.search(\"[$£](([1-9][0-9]*)|(0))([.,][0-9]+)?\", sms.text) else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching based on heuristics\n",
    "\n",
    "A simple heuristic to find spam is to assume that if more than 10% of the message text is written in capitals, there is a good chance it is spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:20.563651Z",
     "start_time": "2021-05-19T19:35:20.207843Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:00<00:00, 28528.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_I_am_free</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_uppercase_words</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.184388</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          j Polarity  Coverage  Overlaps  Conflicts\n",
       "check                     0      [1]  0.010319  0.002243   0.000000\n",
       "free                      1      [1]  0.043517  0.043517   0.006057\n",
       "call_now                  2      [1]  0.004262  0.003813   0.000000\n",
       "regex_I_am_free           3   [0, 1]  0.043517  0.043517   0.006057\n",
       "has_many_uppercase_words  4      [1]  0.184388  0.020637   0.001346"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@labeling_function()\n",
    "def has_many_uppercase_words(sms):\n",
    "    percentage_uppercase = sum([word.isupper() for word in sms.text.split()]) / len(sms.text.split())\n",
    "    \n",
    "    return SPAM if percentage_uppercase > 0.1 else ABSTAIN\n",
    "\n",
    "lfs = [check, free, call_now, regex_I_am_free, has_many_uppercase_words]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assignment\n",
    "\n",
    "Write a labeling function that marks as valid those messages that are shorter than 10 words and do not contain any word written in capitals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:21.341099Z",
     "start_time": "2021-05-19T19:35:21.333785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:00<00:00, 24727.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.008075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.000449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_I_am_free</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.008075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_uppercase_words</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.184388</td>\n",
       "      <td>0.020637</td>\n",
       "      <td>0.001346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_and_no_uppercase</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.277254</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0.003365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          j Polarity  Coverage  Overlaps  Conflicts\n",
       "check                     0      [1]  0.010319  0.003365   0.001122\n",
       "free                      1      [1]  0.043517  0.043517   0.008075\n",
       "call_now                  2      [1]  0.004262  0.004038   0.000449\n",
       "regex_I_am_free           3   [0, 1]  0.043517  0.043517   0.008075\n",
       "has_many_uppercase_words  4      [1]  0.184388  0.020637   0.001346\n",
       "short_and_no_uppercase    5      [0]  0.277254  0.003365   0.003365"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@labeling_function()\n",
    "def short_and_no_uppercase(sms):\n",
    "    toks = sms.text.split()\n",
    "    if len(toks) >= 10: return ABSTAIN\n",
    "    for tok in toks:\n",
    "        if tok == tok.upper(): return ABSTAIN\n",
    "    return HAM\n",
    "\n",
    "lfs = [check, free, call_now, regex_I_am_free, has_many_uppercase_words, short_and_no_uppercase]\n",
    "applier = PandasLFApplier(lfs = lfs)\n",
    "L_train = applier.apply(df = df_train)\n",
    "\n",
    "LFAnalysis(L = L_train, lfs = lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an external statistical model\n",
    "\n",
    "When labeling data, you can use external models whose response can be important information for deciding how to label an example. Snorkel has several built-in integrations in the form of the `Preprocessor` interface, in the example below we will use the `SpaCy` library to perform additional grammatical analysis of the text. However, you will need to download the English language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:31:22.242830Z",
     "start_time": "2021-05-19T19:31:03.524220Z"
    }
   },
   "outputs": [],
   "source": [
    "#!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:31:34.018309Z",
     "start_time": "2021-05-19T19:31:33.068241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[38;5;2m✔ Loaded compatibility table\u001b[0m\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.7.5) =================\u001b[0m\n",
      "\u001b[38;5;4mℹ spaCy installation:\n",
      "/Users/Kuba/Library/Python/3.9/lib/python/site-packages/spacy\u001b[0m\n",
      "\n",
      "NAME             SPACY            VERSION                            \n",
      "en_core_web_sm   >=3.7.2,<3.8.0   \u001b[38;5;2m3.7.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "en_core_web_md   >=3.7.2,<3.8.0   \u001b[38;5;2m3.7.1\u001b[0m   \u001b[38;5;2m✔\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:26.090920Z",
     "start_time": "2021-05-19T19:35:25.099419Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:26.870094Z",
     "start_time": "2021-05-19T19:35:26.810785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "England GPE\n",
      "the United Kingdom GPE\n",
      "Wales ORG\n",
      "Scotland GPE\n",
      "The Irish Sea LOC\n",
      "England GPE\n",
      "the Celtic Sea LOC\n",
      "England GPE\n",
      "Europe LOC\n",
      "the North Sea LOC\n",
      "English LANGUAGE\n",
      "five-eighths CARDINAL\n",
      "Great Britain GPE\n",
      "the North Atlantic LOC\n",
      "over 100 CARDINAL\n",
      "the Isles of Scilly GPE\n",
      "the Isle of Wight GPE\n"
     ]
    }
   ],
   "source": [
    "_text = \"\"\"I don't England is a country that is part of the United Kingdom. \n",
    "It shares land borders with Wales to its west and Scotland to its north. \n",
    "The Irish Sea lies northwest of England and the Celtic Sea to the southwest. \n",
    "England is separated from continental Europe by the North Sea to the east and the \n",
    "English Channel to the south. The country covers five-eighths of the island of \n",
    "Great Britain, which lies in the North Atlantic, and includes over 100 smaller islands, \n",
    "such as the Isles of Scilly and the Isle of Wight.\"\"\"\n",
    "\n",
    "doc = nlp(_text)\n",
    "\n",
    "for e in doc.ents: #ents == named entities\n",
    "    print(e.text, e.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:28.056838Z",
     "start_time": "2021-05-19T19:35:27.497633Z"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "spacy_ = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that short text messages in which a reference to a specific person appears are not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:28.564396Z",
     "start_time": "2021-05-19T19:35:28.552608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:35:29.352633Z",
     "start_time": "2021-05-19T19:35:29.348630Z"
    }
   },
   "outputs": [],
   "source": [
    "@labeling_function(pre=[spacy_])\n",
    "def has_person(sms):\n",
    "    if len(sms.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in sms.doc.ents]):\n",
    "        return HAM\n",
    "    else:\n",
    "        return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:37:09.731132Z",
     "start_time": "2021-05-19T19:35:29.949300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:00<00:00, 23203.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_I_am_free</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_uppercase_words</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.184388</td>\n",
       "      <td>0.026469</td>\n",
       "      <td>0.007178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_person</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.007851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          j Polarity  Coverage  Overlaps  Conflicts\n",
       "check                     0      [1]  0.010319  0.003365   0.001122\n",
       "free                      1      [1]  0.043517  0.043517   0.006954\n",
       "call_now                  2      [1]  0.004262  0.003813   0.000000\n",
       "regex_I_am_free           3   [0, 1]  0.043517  0.043517   0.006954\n",
       "has_many_uppercase_words  4      [1]  0.184388  0.026469   0.007178\n",
       "has_person                5      [0]  0.050022  0.007851   0.007851"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs = [check, free, call_now, regex_I_am_free, has_many_uppercase_words, has_person]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of pre-processing data for labeling would be determining the average word frequency of a document. Below we define a function that determines the average word frequency and we decorate it as an example of a pre-processor. When a text message is sent to the next labeling function, the pre-processor will populate the text message with the average word frequency and, based on that, the labeling function will make a decision (we assume that if the text message contains many rare words then it is spam)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:37:32.970893Z",
     "start_time": "2021-05-19T19:37:32.784823Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordfreq import zipf_frequency\n",
    "from snorkel.preprocess import preprocessor\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def avg_word_freq(sms):\n",
    "    sms.avg_word_freq = sum([zipf_frequency(word, 'en') for word in sms.text.split()]) / len(sms.text.split())\n",
    "    \n",
    "    return sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:37:34.795326Z",
     "start_time": "2021-05-19T19:37:34.790325Z"
    }
   },
   "outputs": [],
   "source": [
    "@labeling_function(pre=[avg_word_freq])\n",
    "def many_rare_words(sms):\n",
    "    return ABSTAIN if sms.avg_word_freq >= 4 else SPAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:37:39.197040Z",
     "start_time": "2021-05-19T19:37:35.984206Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:01<00:00, 4430.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_I_am_free</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_uppercase_words</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.184388</td>\n",
       "      <td>0.044639</td>\n",
       "      <td>0.007178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many_rare_words</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.062135</td>\n",
       "      <td>0.033423</td>\n",
       "      <td>0.008973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_person</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.015029</td>\n",
       "      <td>0.015029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          j Polarity  Coverage  Overlaps  Conflicts\n",
       "check                     0      [1]  0.010319  0.003813   0.001122\n",
       "free                      1      [1]  0.043517  0.043517   0.006954\n",
       "call_now                  2      [1]  0.004262  0.003813   0.000000\n",
       "regex_I_am_free           3   [0, 1]  0.043517  0.043517   0.006954\n",
       "has_many_uppercase_words  4      [1]  0.184388  0.044639   0.007178\n",
       "many_rare_words           5      [1]  0.062135  0.033423   0.008973\n",
       "has_person                6      [0]  0.050022  0.015029   0.015029"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs = [check, free, call_now, regex_I_am_free, has_many_uppercase_words, many_rare_words, has_person]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:37:39.849049Z",
     "start_time": "2021-05-19T19:37:39.827079Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.iloc[L_train[:,6] == SPAM].sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assignment\n",
    "\n",
    "Write a labeling function that marks messages containing more than 3 adjectives as spam. Use the SpaCy library for pre-processing. \n",
    "\n",
    "__Hint__: the following example shows how to read the part-of-speech label for each token from the message being analyzed. For information on all token properties recognized by SpaCy, see [API documentation](https://spacy.io/api/token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:37:41.894274Z",
     "start_time": "2021-05-19T19:37:41.111265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yetunde    PROPN      NNP        Yetunde   \n",
      ",          PUNCT      ,          ,         \n",
      "i          PRON       PRP        I         \n",
      "'m         AUX        VBP        be        \n",
      "sorry      ADJ        JJ         sorry     \n",
      "but        CCONJ      CC         but       \n",
      "moji       ADJ        JJ         moji      \n",
      "and        CCONJ      CC         and       \n",
      "i          PRON       PRP        I         \n",
      "seem       VERB       VBP        seem      \n",
      "too        ADV        RB         too       \n",
      "busy       ADJ        JJ         busy      \n",
      "to         PART       TO         to        \n",
      "be         AUX        VB         be        \n",
      "able       ADJ        JJ         able      \n",
      "to         PART       TO         to        \n",
      "go         VERB       VB         go        \n",
      "shopping   NOUN       NN         shopping  \n",
      ".          PUNCT      .          .         \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "sms = \"Yetunde, i'm sorry but moji and i seem too busy to be able to go shopping.\"\n",
    "\n",
    "for token in nlp(sms):\n",
    "    print(f\"{token.text:<10} {token.pos_:<10} {token.tag_:<10} {token.lemma_:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function(pre = [spacy_])\n",
    "def more_than_3_adj(sms):\n",
    "    return SPAM if [token.pos_ for token in nlp(sms.text)].count(\"ADJ\") > 3 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:25<00:00, 174.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_I_am_free</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_many_uppercase_words</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.184388</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>0.007178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_person</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.007851</td>\n",
       "      <td>0.007851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more_than_3_adj</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.031853</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>0.001795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          j Polarity  Coverage  Overlaps  Conflicts\n",
       "check                     0      [1]  0.010319  0.003813   0.001122\n",
       "free                      1      [1]  0.043517  0.043517   0.006954\n",
       "call_now                  2      [1]  0.004262  0.003813   0.000000\n",
       "regex_I_am_free           3   [0, 1]  0.043517  0.043517   0.006954\n",
       "has_many_uppercase_words  4      [1]  0.184388  0.029385   0.007178\n",
       "has_person                5      [0]  0.050022  0.007851   0.007851\n",
       "more_than_3_adj           6      [1]  0.031853  0.010094   0.001795"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs = [check, free, call_now, regex_I_am_free, has_many_uppercase_words, has_person, more_than_3_adj]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining labeling functions into a single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of labeling functions is not to achieve individually large coverage. Labeling functions are inherently noisy and can make many individual errors. The true utility of labeling functions becomes apparent when multiple functions are combined to form a single model.\n",
    "\n",
    "We will first build a simple model based on majority voting, and then build a more complex model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:10.800140Z",
     "start_time": "2021-05-19T19:37:42.829275Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:00<00:00, 25936.41it/s]\n",
      "100%|██████████| 1114/1114 [00:00<00:00, 25767.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.010319</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.004262</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_I_am_free</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.043517</td>\n",
       "      <td>0.006954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_person</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.050022</td>\n",
       "      <td>0.010094</td>\n",
       "      <td>0.010094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many_rare_words</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.062135</td>\n",
       "      <td>0.015253</td>\n",
       "      <td>0.008973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 j Polarity  Coverage  Overlaps  Conflicts\n",
       "check            0      [1]  0.010319  0.001570   0.001122\n",
       "free             1      [1]  0.043517  0.043517   0.006954\n",
       "call_now         2      [1]  0.004262  0.001570   0.000000\n",
       "regex_I_am_free  3   [0, 1]  0.043517  0.043517   0.006954\n",
       "has_person       4      [0]  0.050022  0.010094   0.010094\n",
       "many_rare_words  5      [1]  0.062135  0.015253   0.008973"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lfs = [check, free, call_now, regex_I_am_free, has_person, many_rare_words]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_test = applier.apply(df=df_test)\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:11.685278Z",
     "start_time": "2021-05-19T19:38:11.659189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.012567</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>0.006284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>call_now</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_I_am_free</th>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>0.063734</td>\n",
       "      <td>0.006284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_person</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.047576</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.010772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>many_rare_words</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.068223</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.008977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 j Polarity  Coverage  Overlaps  Conflicts\n",
       "check            0      [1]  0.012567  0.000898   0.000898\n",
       "free             1      [1]  0.063734  0.063734   0.006284\n",
       "call_now         2      [1]  0.002693  0.000898   0.000000\n",
       "regex_I_am_free  3   [0, 1]  0.063734  0.063734   0.006284\n",
       "has_person       4      [0]  0.047576  0.010772   0.010772\n",
       "many_rare_words  5      [1]  0.068223  0.014363   0.008977"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_test, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:13.165490Z",
     "start_time": "2021-05-19T19:38:12.488067Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:14.046160Z",
     "start_time": "2021-05-19T19:38:14.041527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:14.971642Z",
     "start_time": "2021-05-19T19:38:14.958011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: -1, count: 3847\n",
      "LABEL: 0, count: 178\n",
      "LABEL: 1, count: 433\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "labels, counts = np.unique(preds_train, return_counts=True)\n",
    "\n",
    "for l, c in zip(labels, counts):\n",
    "    print(f\"LABEL: {l}, count: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:16.095821Z",
     "start_time": "2021-05-19T19:38:15.735200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.008]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[200 epochs]: TRAIN:[loss=0.002]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.002]\n",
      " 77%|███████▋  | 385/500 [00:00<00:00, 3840.90epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.001]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3830.92epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:16.707091Z",
     "start_time": "2021-05-19T19:38:16.660020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority voting accuracy: 50.2%\n",
      "Probabilistic model accuracy: 50.4%\n"
     ]
    }
   ],
   "source": [
    "majority_acc = majority_model.score(L=L_test, Y=df_test.label, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(f\"{'Majority voting accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=df_test.label, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "print(f\"{'Probabilistic model accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, some data points will not receive any label. It is necessary to filter out these points before sending the labeling result for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:18.328146Z",
     "start_time": "2021-05-19T19:38:18.257149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4458, 2), (676, 2))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "from snorkel.utils import preds_to_probs, probs_to_preds\n",
    "\n",
    "preds_train, probs_train = label_model.predict(L=L_train, return_probs=True)\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(X=df_train, y=probs_train, L=L_train)\n",
    "df_train.shape, df_train_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we were able to quickly prepare labels for about 650 examples (recall that initially no example in the `df_train` set had labels).\n",
    "\n",
    "The next step will use prepared labels as training data for the actual classifier. We will use simple [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), first pre-processing the input data. Since we are working with text, we will use the [word vector representation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) created based on 5-grams by `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:20.290628Z",
     "start_time": "2021-05-19T19:38:20.140958Z"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.utils import probs_to_preds\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
    "X_test = vectorizer.transform(df_test.text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:21.403376Z",
     "start_time": "2021-05-19T19:38:21.027861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1000.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1000.0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1000.0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=1e3, solver='lbfgs')\n",
    "sklearn_model.fit(X=X_train, y=preds_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:22.426987Z",
     "start_time": "2021-05-19T19:38:22.421221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 55.7%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logistic regression accuracy: {sklearn_model.score(X=X_test, y=df_test.label) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the final model improved the score over the majority vote and the `LabelModel` model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assignment\n",
    "\n",
    "Complete the above calls with functions that you wrote yourself and check whether your functions improve the quality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4458/4458 [00:25<00:00, 174.89it/s]\n",
      "100%|██████████| 1114/1114 [00:06<00:00, 170.15it/s]\n",
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.003]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[200 epochs]: TRAIN:[loss=0.000]\n",
      "INFO:root:[300 epochs]: TRAIN:[loss=0.000]\n",
      " 78%|███████▊  | 392/500 [00:00<00:00, 3916.40epoch/s]INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 3904.73epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.009%\n"
     ]
    }
   ],
   "source": [
    "lfs = [hot, contains_money, has_person, more_than_3_adj]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_test = applier.apply(df=df_test)\n",
    "\n",
    "analysis = LFAnalysis(L=L_train, lfs=lfs)\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=500, log_freq=100, seed = 42)\n",
    "label_acc = label_model.score(L_test, df_test.label, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "\n",
    "preds_train, probs_train = label_model.predict(L=L_train, return_probs = True)\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(X = df_train, y = probs_train, L = L_train)\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs = probs_train_filtered)\n",
    "vectorizer = CountVectorizer(ngram_range=(1,5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
    "X_test = vectorizer.transform(df_test.text.tolist())\n",
    "\n",
    "model = LogisticRegression(C=1e3, solver = 'lbfgs')\n",
    "model.fit(X = X_train, y = preds_train_filtered)\n",
    "\n",
    "accuracy = model.score(X = X_test, y = df_test.label)\n",
    "print(f\"Accuracy: {accuracy * 100:.3f}%\") #Model has improved drastically!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming functions\n",
    "\n",
    "The idea of a transforming function is to perform an atomic transformation of an instance. For data that is an image, typical transformations include cropping, rotating, and changing the color palette. For text data, you can replace words with synonyms, substitute named entities, cut random pieces of text, etc. In the following example we will find types of named entities occurring in the text, and then prepare a simple transformer that will randomly replace occurrences of the `PERSON` entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:38:31.560232Z",
     "start_time": "2021-05-19T19:38:26.866544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [('Yo carlos', 'PERSON'), ('all this weekend', 'DATE')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('2', 'CARDINAL'), ('IT+BOTH', 'FAC')]\n",
      "Entities: []\n",
      "Entities: [('Yar', 'PERSON'), ('4', 'CARDINAL'), ('2', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('Solve d', 'ORG'), ('AfterNoon', 'TIME'), ('1,His', 'CARDINAL'), ('2,Police', 'CARDINAL'), ('2', 'CARDINAL'), ('2', 'CARDINAL'), ('2', 'CARDINAL'), ('U r Brilliant', 'ORG')]\n",
      "Entities: [('WIN', 'ORG'), ('100', 'CARDINAL'), ('every week', 'DATE'), ('NOW Txt', 'WORK_OF_ART'), ('87066', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('1st', 'ORDINAL'), ('TONE', 'ORG'), ('20', 'CARDINAL'), ('every week', 'DATE'), ('just £1.50', 'MONEY'), ('2', 'CARDINAL')]\n",
      "Entities: [('Keris bin doin', 'PERSON')]\n",
      "Entities: []\n",
      "Entities: [('as much as 2 hours', 'CARDINAL')]\n",
      "Entities: [('House', 'ORG'), ('January', 'DATE')]\n",
      "Entities: [('today', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('2', 'CARDINAL'), ('first', 'ORDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('Love', 'WORK_OF_ART')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('One', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: [('helens fone', 'PERSON'), ('2', 'CARDINAL'), ('Kate', 'PERSON')]\n",
      "Entities: [('09061221066', 'CARDINAL'), ('28 days', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('Iyo kothi chikku', 'PERSON'), ('chikku:-);-)B-', 'ORG')]\n",
      "Entities: [('4', 'CARDINAL')]\n",
      "Entities: [('first', 'ORDINAL')]\n",
      "Entities: [('Dip', 'PERSON')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('tonight', 'TIME')]\n",
      "Entities: [('URGOIN OUTL8R', 'LOC'), ('REALLYNEED', 'ORG'), ('U NO THECD ISV.IMPORTANT', 'ORG'), ('2MORO', 'CARDINAL')]\n",
      "Entities: [('a good week', 'DATE')]\n",
      "Entities: [('Todays Vodafone', 'ORG'), ('4882', 'DATE'), ('350', 'MONEY'), ('350', 'MONEY')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('Half Price', 'ORG'), ('12', 'CARDINAL'), ('500', 'CARDINAL'), ('ntwk', 'PERSON'), ('100', 'CARDINAL')]\n",
      "Entities: [('2MOROW 28/5', 'CARDINAL'), ('NICHOLS', 'PERSON'), ('2', 'CARDINAL'), ('info', 'PERSON'), ('07946746291/07880867867', 'DATE')]\n",
      "Entities: [('Thnx', 'ORG'), ('2nite', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: [('9', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: [('2', 'CARDINAL'), ('89938', 'DATE'), ('1.50ea', 'MONEY'), ('OTBox', 'ORG'), ('7WS', 'LAW')]\n",
      "Entities: [('kettoda manda', 'PERSON')]\n",
      "Entities: [('2', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('one', 'CARDINAL'), ('4', 'CARDINAL'), ('100', 'CARDINAL'), ('G.B.', 'GPE'), ('ENTER', 'ORG')]\n",
      "Entities: [('2', 'CARDINAL'), ('Yar', 'PERSON')]\n",
      "Entities: [('WIN', 'ORG'), ('100', 'CARDINAL'), ('every week', 'DATE'), ('NOW Txt', 'WORK_OF_ART'), ('87066', 'CARDINAL'), ('SkillGame', 'PERSON'), ('150ppermessSubscription', 'CARDINAL')]\n",
      "Entities: [('This year', 'DATE')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('ONLY £10', 'MONEY'), ('TXTAUCTION!Txt', 'DATE'), ('No:81151 &', 'ORG')]\n",
      "Entities: [('yesterday', 'DATE'), ('a great week', 'DATE'), ('Abiola', 'ORG')]\n",
      "Entities: [('Reference T91', 'PERSON'), ('GBP 4 per week', 'DATE'), ('09057039994', 'DATE')]\n",
      "Entities: [('two', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('ROMCAPspam', 'NORP')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('john', 'PERSON'), ('nigeria', 'GPE'), ('2years', 'CARDINAL')]\n",
      "Entities: [('kettoda manda', 'PERSON')]\n",
      "Entities: [('2', 'CARDINAL'), ('1', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('chikku', 'PERSON'), ('il send aftr  &lt;#&gt', 'PERSON')]\n",
      "Entities: [('about 3', 'CARDINAL')]\n",
      "Entities: [('mummy', 'PERSON')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('today', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('last year', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('2', 'CARDINAL'), ('3', 'CARDINAL'), ('today', 'DATE')]\n",
      "Entities: [('one day', 'DATE')]\n",
      "Entities: [('Mila', 'PERSON'), ('UK', 'GPE'), ('UK', 'GPE'), ('69866.18', 'CARDINAL'), ('1.50', 'MONEY')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('chikku nange', 'PERSON')]\n",
      "Entities: []\n",
      "Entities: [('Bt', 'GPE'), ('2', 'CARDINAL'), ('about 2', 'CARDINAL'), ('Boost', 'PERSON'), ('Thy', 'PERSON'), ('2gthr', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('half an hour', 'TIME')]\n",
      "Entities: []\n",
      "Entities: [('Nokia Phone', 'ORG'), ('40', 'CARDINAL'), ('GB', 'GPE'), ('iPod', 'ORG'), ('500', 'MONEY'), ('83355', 'CARDINAL'), ('IBHltd', 'ORG')]\n",
      "Entities: []\n",
      "Entities: [('the other day', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('5000', 'MONEY'), ('4', 'CARDINAL'), ('20M12AQ', 'CARDINAL'), ('150ppm', 'CARDINAL'), ('16+', 'DATE')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('Gettin', 'ORG')]\n",
      "Entities: [('25p 4', 'MONEY'), ('Txt Tone', 'PERSON'), ('08701417012', 'DATE'), ('2', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: [('Suganya', 'GPE')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('89555', 'DATE'), ('150p', 'CARDINAL'), ('18', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: [('Jordan', 'GPE')]\n",
      "Entities: []\n",
      "Entities: [('FIRST', 'ORDINAL'), ('87131', 'DATE'), ('2814032 16', 'DATE'), ('1st', 'ORDINAL'), ('3x£150pw', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('some hours', 'TIME')]\n",
      "Entities: [('45', 'CARDINAL'), ('0121', 'CARDINAL'), ('2025050', 'DATE'), ('www.shortbreaks.org.uk', 'ORG')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('62468', 'DATE')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('500 pounds', 'QUANTITY'), ('86688', 'DATE'), ('08718720201', 'CARDINAL')]\n",
      "Entities: [('first', 'ORDINAL')]\n",
      "Entities: [('Night night', 'TIME'), ('tomorrow', 'DATE')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('Pink Panther', 'PERSON'), ('1', 'CARDINAL'), ('Hoody', 'PERSON'), ('4', 'CARDINAL')]\n",
      "Entities: [('1hr', 'ORDINAL')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('audrey', 'PERSON')]\n",
      "Entities: []\n",
      "Entities: [('One', 'CARDINAL')]\n",
      "Entities: [('Nah', 'PERSON')]\n",
      "Entities: [('Dave', 'PERSON'), ('the other day', 'DATE'), ('2GETHA', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('08081263000', 'CARDINAL'), ('BT', 'ORG')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('ten bucks', 'MONEY')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('18 days', 'DATE'), ('daily', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('BRAND', 'ORG'), ('Nokia', 'ORG'), ('7250', 'DATE'), ('4', 'CARDINAL'), ('today', 'DATE'), ('Txt NOKIA', 'PERSON'), ('86021', 'DATE')]\n",
      "Entities: [(\"Red;i'm\", 'PERSON'), ('luv wid', 'LOC'), ('realy', 'GPE'), ('realy wana', 'ORG'), ('one', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: [('3 years', 'DATE')]\n",
      "Entities: [('4', 'CARDINAL'), ('2', 'CARDINAL'), ('singapore', 'GPE')]\n",
      "Entities: [('+449071512431 URGENT', 'ORG'), ('2nd', 'ORDINAL'), ('U!U', 'WORK_OF_ART'), ('150ppm', 'CARDINAL'), ('50', 'CARDINAL')]\n",
      "Entities: [('Kay', 'PERSON')]\n",
      "Entities: [('june', 'DATE')]\n",
      "Entities: [('That day', 'DATE')]\n",
      "Entities: [('LOVE', 'ORG')]\n",
      "Entities: []\n",
      "Entities: [('one', 'CARDINAL')]\n",
      "Entities: [('2', 'CARDINAL'), ('1000', 'MONEY'), ('4* holiday', 'DATE'), ('2', 'CARDINAL')]\n",
      "Entities: [('Last weekends', 'DATE'), ('1000', 'MONEY'), ('GUARANTEED', 'GPE'), ('Code K52', 'PERSON'), ('12hrs', 'CARDINAL'), ('150ppm', 'CARDINAL')]\n",
      "Entities: [('next week', 'DATE'), ('this weekend', 'DATE')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('Sry da', 'PERSON')]\n",
      "Entities: [('Yes.mum', 'NORP')]\n",
      "Entities: []\n",
      "Entities: [('Arabian', 'NORP'), ('Mmmmmm', 'NORP'), ('Yummy', 'PERSON')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('Jay', 'PERSON')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('monday', 'DATE')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('2.', 'CARDINAL')]\n",
      "Entities: [('dead!Well Jez', 'ORG')]\n",
      "Entities: [('yesterday', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('Friday', 'DATE'), ('this year', 'DATE')]\n",
      "Entities: [('600', 'CARDINAL'), ('B. Barry', 'PERSON'), ('C. Ben', 'PERSON')]\n",
      "Entities: [('Nvm', 'PERSON')]\n",
      "Entities: []\n",
      "Entities: []\n",
      "Entities: [('Morning', 'TIME')]\n",
      "Entities: [('Natalja', 'PERSON'), ('25', 'CARDINAL'), ('62468', 'DATE')]\n",
      "Entities: []\n",
      "Entities: [('Spring', 'DATE')]\n",
      "Entities: [('88800', 'CARDINAL'), ('08718711108', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: [('4', 'CARDINAL')]\n",
      "Entities: []\n",
      "Entities: [('4 dinner lor', 'QUANTITY')]\n",
      "Entities: [('raiden', 'ORG'), ('buff', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for doc in nlp.pipe(df_train.text.sample(frac=0.05)):\n",
    "    print(f\"Entities: {[(e.text, e.label_) for e in doc.ents]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:40:36.945027Z",
     "start_time": "2021-05-19T19:39:12.256235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nah',\n",
       " 'Melle Melle',\n",
       " 'Mark',\n",
       " 'Yummy',\n",
       " 'Mark',\n",
       " 'Mallika Sherawat',\n",
       " 'Matrix3',\n",
       " 'ShrAcomOrSglSuplt)10',\n",
       " 'LS1 3AJ',\n",
       " 'Wah']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_entities = []\n",
    "\n",
    "for doc in nlp.pipe(df_train.text):\n",
    "    for e in doc.ents:\n",
    "        if e.label_ == 'PERSON':\n",
    "            person_entities.append(e.text)\n",
    "        \n",
    "person_entities[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:42:03.662025Z",
     "start_time": "2021-05-19T19:42:02.919683Z"
    }
   },
   "outputs": [],
   "source": [
    "from snorkel.augmentation import transformation_function\n",
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)\n",
    "\n",
    "@transformation_function(pre=[spacy_])\n",
    "def random_person_ner(sms):\n",
    "    person_ners = [e.text for e in sms.doc.ents]\n",
    "    \n",
    "    if person_ners:\n",
    "        person_to_replace = np.random.choice(person_ners)\n",
    "        person_to_add = np.random.choice(person_entities)\n",
    "        sms.text = sms.text.replace(person_to_replace, person_to_add)\n",
    "    return sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example of transformation could be using WordNet to find synonyms for words. However, this requires downloading a corpus of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:42:20.633409Z",
     "start_time": "2021-05-19T19:42:20.093443Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Kuba/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:42:25.058494Z",
     "start_time": "2021-05-19T19:42:25.054333Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_synonym(word):\n",
    "    \n",
    "    synsets = wordnet.synsets(word)\n",
    "    \n",
    "    if synsets:\n",
    "        words = [lemma.name() for lemma in synsets[0].lemmas()]\n",
    "        \n",
    "        return np.random.choice([w.replace(\"_\", \" \") for w in words])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:42:27.153320Z",
     "start_time": "2021-05-19T19:42:27.148396Z"
    }
   },
   "outputs": [],
   "source": [
    "@transformation_function()\n",
    "def replace_words_with_synonym(sms, num_replacements=5):\n",
    "\n",
    "    words = sms.text.split()\n",
    "    \n",
    "    for _ in range(num_replacements):\n",
    "        word_idx = np.random.choice(range(len(words)))\n",
    "        synonym = get_synonym(words[word_idx])\n",
    "        if synonym:\n",
    "            words[word_idx] = synonym\n",
    "        \n",
    "    sms.text = ' '.join(words)\n",
    "    return sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compare the original text message content with the transformed versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:42:31.366022Z",
     "start_time": "2021-05-19T19:42:31.361290Z"
    }
   },
   "outputs": [],
   "source": [
    "# source: https://github.com/snorkel-team/snorkel-tutorials/blob/master/spam/utils.py\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def preview_tfs(df, tfs):\n",
    "    transformed_examples = []\n",
    "    for f in tfs:\n",
    "        for i, row in df.iterrows():\n",
    "            transformed_or_none = f(row)\n",
    "            # If TF returned a transformed example, record it in dict and move to next TF.\n",
    "            if transformed_or_none is not None:\n",
    "                transformed_examples.append(\n",
    "                    OrderedDict(\n",
    "                        {\n",
    "                            \"TF Name\": f.name,\n",
    "                            \"Original Text\": row.text,\n",
    "                            \"Transformed Text\": transformed_or_none.text,\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "    return pd.DataFrame(transformed_examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:46:55.348701Z",
     "start_time": "2021-05-19T19:46:54.714091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TF Name</th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Transformed Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random_person_ner</td>\n",
       "      <td>Cramps stopped. Going back to sleep</td>\n",
       "      <td>Yar stopped. Going back to sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_person_ner</td>\n",
       "      <td>URGENT! We are trying to contact U. Todays draw shows that you have won a £800 prize GUARANTEED. Call 09050001808 from land line. Claim M95. Valid12hrs only</td>\n",
       "      <td>URGENT! We are trying to contact Drop draw shows that you have won a £800 prize GUARANTEED. Call 09050001808 from land line. Claim M95. Valid12hrs only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_person_ner</td>\n",
       "      <td>God's love has no limit. God's grace has no measure. God's power has no boundaries. May u have God's endless blessings always in ur life...!! Gud ni8</td>\n",
       "      <td>God's love has no limit. God's grace has no measure. God's power has no boundaries. Clos1 Lvblefrnd Jstfrnd u have God's endless blessings always in ur life...!! Gud ni8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>random_person_ner</td>\n",
       "      <td>Urgent! call 09061749602 from Landline. Your complimentary 4* Tenerife Holiday or £10,000 cash await collection SAE T&amp;Cs BOX 528 HP20 1YF 150ppm 18+</td>\n",
       "      <td>Urgent! call 09061749602 from Landline. Your complimentary 4* Tenerife Holiday or £apps da cash await collection SAE T&amp;Cs BOX 528 HP20 1YF 150ppm 18+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>random_person_ner</td>\n",
       "      <td>After the drug she will be able to eat.</td>\n",
       "      <td>After the drug she will be able to eat.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>replace_words_with_synonym</td>\n",
       "      <td>Nothing but we jus tot u would ask cos u ba gua... But we went mt faber yest... Yest jus went out already mah so today not going out... Jus call lor...</td>\n",
       "      <td>Nothing but we jus tot u would enquire cos u ba gua... But we went mt faber yest... Yest jus went out already mah soh today not going out... Jus call lor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>replace_words_with_synonym</td>\n",
       "      <td>Dai i downloaded but there is only exe file which i can only run that exe after installing.</td>\n",
       "      <td>Dai i downloaded but there be only exe file which i can only run that exe after installing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>replace_words_with_synonym</td>\n",
       "      <td>Say this slowly.? GOD,I LOVE YOU &amp;amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp;amp; u c miracle tomorrow, do it,pls,pls do it...</td>\n",
       "      <td>Say this slowly.? GOD,I LOVE YOU &amp;amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp;amp; u c miracle tomorrow, do it,pls,pls do it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>replace_words_with_synonym</td>\n",
       "      <td>I'm home.</td>\n",
       "      <td>I'm home.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>replace_words_with_synonym</td>\n",
       "      <td>Hey... are you going to quit soon? Xuhui and i working till end of the month</td>\n",
       "      <td>Hey... are you departure to quit soon? Xuhui and i working till terminal of the month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>892 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        TF Name  \\\n",
       "0             random_person_ner   \n",
       "1             random_person_ner   \n",
       "2             random_person_ner   \n",
       "3             random_person_ner   \n",
       "4             random_person_ner   \n",
       "..                          ...   \n",
       "887  replace_words_with_synonym   \n",
       "888  replace_words_with_synonym   \n",
       "889  replace_words_with_synonym   \n",
       "890  replace_words_with_synonym   \n",
       "891  replace_words_with_synonym   \n",
       "\n",
       "                                                                                                                                                           Original Text  \\\n",
       "0                                                                                                                                    Cramps stopped. Going back to sleep   \n",
       "1           URGENT! We are trying to contact U. Todays draw shows that you have won a £800 prize GUARANTEED. Call 09050001808 from land line. Claim M95. Valid12hrs only   \n",
       "2                  God's love has no limit. God's grace has no measure. God's power has no boundaries. May u have God's endless blessings always in ur life...!! Gud ni8   \n",
       "3                   Urgent! call 09061749602 from Landline. Your complimentary 4* Tenerife Holiday or £10,000 cash await collection SAE T&Cs BOX 528 HP20 1YF 150ppm 18+   \n",
       "4                                                                                                                                After the drug she will be able to eat.   \n",
       "..                                                                                                                                                                   ...   \n",
       "887              Nothing but we jus tot u would ask cos u ba gua... But we went mt faber yest... Yest jus went out already mah so today not going out... Jus call lor...   \n",
       "888                                                                          Dai i downloaded but there is only exe file which i can only run that exe after installing.   \n",
       "889  Say this slowly.? GOD,I LOVE YOU &amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp; u c miracle tomorrow, do it,pls,pls do it...   \n",
       "890                                                                                                                                                            I'm home.   \n",
       "891                                                                                        Hey... are you going to quit soon? Xuhui and i working till end of the month    \n",
       "\n",
       "                                                                                                                                                              Transformed Text  \n",
       "0                                                                                                                                             Yar stopped. Going back to sleep  \n",
       "1                      URGENT! We are trying to contact Drop draw shows that you have won a £800 prize GUARANTEED. Call 09050001808 from land line. Claim M95. Valid12hrs only  \n",
       "2    God's love has no limit. God's grace has no measure. God's power has no boundaries. Clos1 Lvblefrnd Jstfrnd u have God's endless blessings always in ur life...!! Gud ni8  \n",
       "3                        Urgent! call 09061749602 from Landline. Your complimentary 4* Tenerife Holiday or £apps da cash await collection SAE T&Cs BOX 528 HP20 1YF 150ppm 18+  \n",
       "4                                                                                                                                      After the drug she will be able to eat.  \n",
       "..                                                                                                                                                                         ...  \n",
       "887               Nothing but we jus tot u would enquire cos u ba gua... But we went mt faber yest... Yest jus went out already mah soh today not going out... Jus call lor...  \n",
       "888                                                                                Dai i downloaded but there be only exe file which i can only run that exe after installing.  \n",
       "889        Say this slowly.? GOD,I LOVE YOU &amp; I NEED YOU,CLEAN MY HEART WITH YOUR BLOOD.Send this to Ten special people &amp; u c miracle tomorrow, do it,pls,pls do it...  \n",
       "890                                                                                                                                                                  I'm home.  \n",
       "891                                                                                      Hey... are you departure to quit soon? Xuhui and i working till terminal of the month  \n",
       "\n",
       "[892 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs = [random_person_ner, replace_words_with_synonym]\n",
    "\n",
    "preview_tfs(df_train.sample(frac=0.1), tfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying transforming functions requires some policy defining the order and number of transformations. In the example below, two transformation functions are drawn at random and this sequence of two functions is applied twice to each data point. As a result, we triple the size of the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:48:27.795346Z",
     "start_time": "2021-05-19T19:48:18.367019Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446/446 [00:02<00:00, 155.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.augmentation import RandomPolicy, PandasTFApplier\n",
    "\n",
    "random_policy = RandomPolicy(len(tfs), sequence_length=2, n_per_original=2, keep_original=True)\n",
    "\n",
    "tf_applier = PandasTFApplier(tfs, random_policy)\n",
    "\n",
    "df_train_sample = df_train.sample(frac=0.1)\n",
    "df_train_augmented = tf_applier.apply(df_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-19T19:48:30.188103Z",
     "start_time": "2021-05-19T19:48:30.181349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((446, 2), (1338, 2))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_sample.shape, df_train_augmented.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assignment\n",
    "\n",
    "Modify the transforming function ``replace_words_with_synonym()`` so that you can restrict the replacement of words with synonyms only for specific parts of speech (e.g., replace only nouns or verbs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transformation_function()\n",
    "def replace_words_with_synonym_specific_pos(sms, num_replacements=5):\n",
    "    words = sms.text.split()\n",
    "    poss = [\"ADJ\", \"NOUN\", \"VERB\", \"PRON\"]\n",
    "    tokens_pos = [token.pos_ for token in nlp(sms.text)]\n",
    "    it, changes = (0, 0) #we either want 5 changes or 15 tries to make some changes in sms; it is done not to have infinite loops\n",
    "    \n",
    "    while it < 3 * num_replacements and changes < num_replacements:\n",
    "        word_idx = np.random.choice(range(len(words)))\n",
    "        if (tokens_pos[word_idx] in poss):\n",
    "            synonym = get_synonym(words[word_idx])\n",
    "            if synonym:\n",
    "                changes += 1\n",
    "                words[word_idx] = synonym\n",
    "        it += 1\n",
    "        \n",
    "    sms.text = ' '.join(words)\n",
    "    return sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446/446 [00:07<00:00, 61.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2098                                                                                         Are you the cutest girl in the world or what\n",
      "2098                                                                                    Are you the cut young woman in the cosmos or what\n",
      "2098                                                                                 Are you the cut young woman in the existence or what\n",
      "2586                                                                                         I will be outside office take all from there\n",
      "2586                                                               atomic number John will be outside business office take all from there\n",
      "2586                                                          atomic number NICHOLS will be outside business office return all from there\n",
      "5053                      Tick, tick, tick .... Where are you ? I could die of loneliness you know ! *pouts* *stomps feet* I need you ...\n",
      "5053               Wait.i, tick, tick .... Where are you ? I could die of loneliness you know ! *pouts* *stomps feet* iodine need you ...\n",
      "5053    Tick, tick, tick .... Where are you ? I could dice of solitariness you know ! *pouts* *stomps feet* atomic number 53 need you ...\n",
      "1178                                                                                                           Just nw i came to hme da..\n",
      "1178                                                                                                           Just nw i come to hme da..\n",
      "1178                                                                                                      Just nw iodine seed to hme da..\n",
      "5440                                                                                        Thank you. do you generally date the brothas?\n",
      "5440                                                                                     give thanks you. do you mostly date the brothas?\n",
      "5440                                                              give thanks you. do you for the most part day of the month the brothas?\n",
      "Name: text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tfs = [random_person_ner, replace_words_with_synonym_specific_pos]\n",
    "\n",
    "preview_tfs(df_train.sample(frac=0.1), tfs)\n",
    "\n",
    "random_policy = RandomPolicy(len(tfs), sequence_length=2, n_per_original=2, keep_original=True)\n",
    "\n",
    "tf_applier = PandasTFApplier(tfs, random_policy)\n",
    "\n",
    "df_train_sample = df_train.sample(frac=0.1)\n",
    "df_train_augmented = tf_applier.apply(df_train_sample)\n",
    "\n",
    "print(df_train_augmented.text[:15])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
